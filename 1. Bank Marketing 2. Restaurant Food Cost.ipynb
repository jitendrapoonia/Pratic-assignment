{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7de11d1",
   "metadata": {},
   "source": [
    "# BANK MARKETING: Predicting Whether The Customer Will Subscribe To Term Deposit (FIXED DEPOSIT) or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f0c1b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID  age         job   marital  education default  balance housing loan  \\\n",
      "0  26110   56      admin.   married    unknown      no     1933      no   no   \n",
      "1  40576   31     unknown   married  secondary      no        3      no   no   \n",
      "2  15320   27    services   married  secondary      no      891     yes   no   \n",
      "3  43962   57  management  divorced   tertiary      no     3287      no   no   \n",
      "4  29842   31  technician   married  secondary      no      119     yes   no   \n",
      "\n",
      "     contact  day month  duration  campaign  pdays  previous poutcome  \\\n",
      "0  telephone   19   nov        44         2     -1         0  unknown   \n",
      "1   cellular   20   jul        91         2     -1         0  unknown   \n",
      "2   cellular   18   jul       240         1     -1         0  unknown   \n",
      "3   cellular   22   jun       867         1     84         3  success   \n",
      "4   cellular    4   feb       380         1     -1         0  unknown   \n",
      "\n",
      "  subscribed  \n",
      "0         no  \n",
      "1         no  \n",
      "2         no  \n",
      "3        yes  \n",
      "4         no  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31647 entries, 0 to 31646\n",
      "Data columns (total 18 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   ID          31647 non-null  int64 \n",
      " 1   age         31647 non-null  int64 \n",
      " 2   job         31647 non-null  object\n",
      " 3   marital     31647 non-null  object\n",
      " 4   education   31647 non-null  object\n",
      " 5   default     31647 non-null  object\n",
      " 6   balance     31647 non-null  int64 \n",
      " 7   housing     31647 non-null  object\n",
      " 8   loan        31647 non-null  object\n",
      " 9   contact     31647 non-null  object\n",
      " 10  day         31647 non-null  int64 \n",
      " 11  month       31647 non-null  object\n",
      " 12  duration    31647 non-null  int64 \n",
      " 13  campaign    31647 non-null  int64 \n",
      " 14  pdays       31647 non-null  int64 \n",
      " 15  previous    31647 non-null  int64 \n",
      " 16  poutcome    31647 non-null  object\n",
      " 17  subscribed  31647 non-null  object\n",
      "dtypes: int64(8), object(10)\n",
      "memory usage: 4.3+ MB\n",
      "None\n",
      "ID            0\n",
      "age           0\n",
      "job           0\n",
      "marital       0\n",
      "education     0\n",
      "default       0\n",
      "balance       0\n",
      "housing       0\n",
      "loan          0\n",
      "contact       0\n",
      "day           0\n",
      "month         0\n",
      "duration      0\n",
      "campaign      0\n",
      "pdays         0\n",
      "previous      0\n",
      "poutcome      0\n",
      "subscribed    0\n",
      "dtype: int64\n",
      "                  ID           age          job  marital  education default  \\\n",
      "count   31647.000000  31647.000000        31647    31647      31647   31647   \n",
      "unique           NaN           NaN           12        3          4       2   \n",
      "top              NaN           NaN  blue-collar  married  secondary      no   \n",
      "freq             NaN           NaN         6842    19095      16224   31062   \n",
      "mean    22563.972162     40.957247          NaN      NaN        NaN     NaN   \n",
      "std     13075.936990     10.625134          NaN      NaN        NaN     NaN   \n",
      "min         2.000000     18.000000          NaN      NaN        NaN     NaN   \n",
      "25%     11218.000000     33.000000          NaN      NaN        NaN     NaN   \n",
      "50%     22519.000000     39.000000          NaN      NaN        NaN     NaN   \n",
      "75%     33879.500000     48.000000          NaN      NaN        NaN     NaN   \n",
      "max     45211.000000     95.000000          NaN      NaN        NaN     NaN   \n",
      "\n",
      "              balance housing   loan   contact           day  month  \\\n",
      "count    31647.000000   31647  31647     31647  31647.000000  31647   \n",
      "unique            NaN       2      2         3           NaN     12   \n",
      "top               NaN     yes     no  cellular           NaN    may   \n",
      "freq              NaN   17584  26516     20423           NaN   9669   \n",
      "mean      1363.890258     NaN    NaN       NaN     15.835466    NaN   \n",
      "std       3028.304293     NaN    NaN       NaN      8.337097    NaN   \n",
      "min      -8019.000000     NaN    NaN       NaN      1.000000    NaN   \n",
      "25%         73.000000     NaN    NaN       NaN      8.000000    NaN   \n",
      "50%        450.000000     NaN    NaN       NaN     16.000000    NaN   \n",
      "75%       1431.000000     NaN    NaN       NaN     21.000000    NaN   \n",
      "max     102127.000000     NaN    NaN       NaN     31.000000    NaN   \n",
      "\n",
      "            duration      campaign         pdays      previous poutcome  \\\n",
      "count   31647.000000  31647.000000  31647.000000  31647.000000    31647   \n",
      "unique           NaN           NaN           NaN           NaN        4   \n",
      "top              NaN           NaN           NaN           NaN  unknown   \n",
      "freq             NaN           NaN           NaN           NaN    25929   \n",
      "mean      258.113534      2.765697     39.576042      0.574272      NaN   \n",
      "std       257.118973      3.113830     99.317592      2.422529      NaN   \n",
      "min         0.000000      1.000000     -1.000000      0.000000      NaN   \n",
      "25%       104.000000      1.000000     -1.000000      0.000000      NaN   \n",
      "50%       180.000000      2.000000     -1.000000      0.000000      NaN   \n",
      "75%       318.500000      3.000000     -1.000000      0.000000      NaN   \n",
      "max      4918.000000     63.000000    871.000000    275.000000      NaN   \n",
      "\n",
      "       subscribed  \n",
      "count       31647  \n",
      "unique          2  \n",
      "top            no  \n",
      "freq        27932  \n",
      "mean          NaN  \n",
      "std           NaN  \n",
      "min           NaN  \n",
      "25%           NaN  \n",
      "50%           NaN  \n",
      "75%           NaN  \n",
      "max           NaN  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'day_of_week'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'day_of_week'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_cols:\n\u001b[0;32m     32\u001b[0m     label_encoders[col] \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m---> 33\u001b[0m     train_data[col] \u001b[38;5;241m=\u001b[39m label_encoders[col]\u001b[38;5;241m.\u001b[39mfit_transform(train_data[col])\n\u001b[0;32m     34\u001b[0m     test_data[col] \u001b[38;5;241m=\u001b[39m label_encoders[col]\u001b[38;5;241m.\u001b[39mfit_transform(test_data[col])\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Check the encoded data\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'day_of_week'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "train_url = \"https://raw.githubusercontent.com/FlipRoboTechnologies/ML-Datasets/main/Bank%20Marketing/termdeposit_train.csv\"\n",
    "test_url = \"https://raw.githubusercontent.com/FlipRoboTechnologies/ML-Datasets/main/Bank%20Marketing/termdeposit_test.csv\"\n",
    "\n",
    "train_data = pd.read_csv(train_url)\n",
    "test_data = pd.read_csv(test_url)\n",
    "\n",
    "print(train_data.head())\n",
    "\n",
    "print(train_data.info())\n",
    "\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "print(train_data.describe(include='all'))\n",
    "\n",
    "categorical_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    train_data[col] = label_encoders[col].fit_transform(train_data[col])\n",
    "    test_data[col] = label_encoders[col].fit_transform(test_data[col])\n",
    "\n",
    "print(train_data.head())\n",
    "\n",
    "# Separate features and target variable\n",
    "X = train_data.drop(['ID', 'subscribed'], axis=1)\n",
    "y = train_data['subscribed'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_prob = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred)\n",
    "recall = recall_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "roc_auc = roc_auc_score(y_val, y_pred_prob)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.2f}\")\n",
    "\n",
    "X_test = test_data.drop(['ID'], axis=1)\n",
    "\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({'ID': test_data['ID'], 'subscribed': test_predictions})\n",
    "submission['subscribed'] = submission['subscribed'].apply(lambda x: 'yes' if x == 1 else 'no')\n",
    "\n",
    "submission.to_csv('termdeposit_predictions.csv', index=False)\n",
    "print(\"Predictions saved to termdeposit_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6ffa29",
   "metadata": {},
   "source": [
    "# Restaurant Food Cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75cdcc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               TITLE  RESTAURANT_ID  \\\n",
      "0      CASUAL DINING           9438   \n",
      "1  CASUAL DINING,BAR          13198   \n",
      "2      CASUAL DINING          10915   \n",
      "3        QUICK BITES           6346   \n",
      "4     DESSERT PARLOR          15387   \n",
      "\n",
      "                                     CUISINES  \\\n",
      "0                 Malwani, Goan, North Indian   \n",
      "1              Asian, Modern Indian, Japanese   \n",
      "2  North Indian, Chinese, Biryani, Hyderabadi   \n",
      "3                            Tibetan, Chinese   \n",
      "4                                    Desserts   \n",
      "\n",
      "                                     TIME     CITY        LOCALITY RATING  \\\n",
      "0  11am – 4pm, 7:30pm – 11:30pm (Mon-Sun)    Thane  Dombivali East    3.6   \n",
      "1                    6pm – 11pm (Mon-Sun)  Chennai       Ramapuram    4.2   \n",
      "2     11am – 3:30pm, 7pm – 11pm (Mon-Sun)  Chennai      Saligramam    3.8   \n",
      "3                 11:30am – 1am (Mon-Sun)   Mumbai     Bandra West    4.1   \n",
      "4                    11am – 1am (Mon-Sun)   Mumbai     Lower Parel    3.8   \n",
      "\n",
      "       VOTES  COST  \n",
      "0   49 votes  1200  \n",
      "1   30 votes  1500  \n",
      "2  221 votes   800  \n",
      "3   24 votes   800  \n",
      "4  165 votes   300  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12690 entries, 0 to 12689\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   TITLE          11687 non-null  object\n",
      " 1   RESTAURANT_ID  12690 non-null  int64 \n",
      " 2   CUISINES       12690 non-null  object\n",
      " 3   TIME           12690 non-null  object\n",
      " 4   CITY           12578 non-null  object\n",
      " 5   LOCALITY       12592 non-null  object\n",
      " 6   RATING         12688 non-null  object\n",
      " 7   VOTES          11486 non-null  object\n",
      " 8   COST           12690 non-null  int64 \n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 892.4+ KB\n",
      "None\n",
      "TITLE            1003\n",
      "RESTAURANT_ID       0\n",
      "CUISINES            0\n",
      "TIME                0\n",
      "CITY              112\n",
      "LOCALITY           98\n",
      "RATING              2\n",
      "VOTES            1204\n",
      "COST                0\n",
      "dtype: int64\n",
      "              TITLE  RESTAURANT_ID      CUISINES                   TIME  \\\n",
      "count         11687   12690.000000         12690                  12690   \n",
      "unique          112            NaN          4155                   2689   \n",
      "top     QUICK BITES            NaN  South Indian  11am – 11pm (Mon-Sun)   \n",
      "freq           4218            NaN           532                   1415   \n",
      "mean            NaN    7759.134121           NaN                    NaN   \n",
      "std             NaN    4504.874150           NaN                    NaN   \n",
      "min             NaN       0.000000           NaN                    NaN   \n",
      "25%             NaN    3863.250000           NaN                    NaN   \n",
      "50%             NaN    7740.000000           NaN                    NaN   \n",
      "75%             NaN   11688.750000           NaN                    NaN   \n",
      "max             NaN   15573.000000           NaN                    NaN   \n",
      "\n",
      "           CITY    LOCALITY RATING     VOTES          COST  \n",
      "count     12578       12592  12688     11486  12690.000000  \n",
      "unique      359        1416     32      1847           NaN  \n",
      "top     Chennai  Gachibowli    3.9  44 votes           NaN  \n",
      "freq       2174         166   1238        71           NaN  \n",
      "mean        NaN         NaN    NaN       NaN    655.252246  \n",
      "std         NaN         NaN    NaN       NaN    627.003540  \n",
      "min         NaN         NaN    NaN       NaN     20.000000  \n",
      "25%         NaN         NaN    NaN       NaN    300.000000  \n",
      "50%         NaN         NaN    NaN       NaN    500.000000  \n",
      "75%         NaN         NaN    NaN       NaN    800.000000  \n",
      "max         NaN         NaN    NaN       NaN  14000.000000  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- COST\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmost_frequent\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m train_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(imputer\u001b[38;5;241m.\u001b[39mfit_transform(train_data), columns\u001b[38;5;241m=\u001b[39mtrain_data\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m---> 31\u001b[0m test_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(imputer\u001b[38;5;241m.\u001b[39mtransform(test_data), columns\u001b[38;5;241m=\u001b[39mtest_data\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Encode categorical variables\u001b[39;00m\n\u001b[0;32m     34\u001b[0m label_encoders \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:527\u001b[0m, in \u001b[0;36mSimpleImputer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Impute all missing values in `X`.\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \n\u001b[0;32m    514\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;124;03m    `X` with imputed values.\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    525\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 527\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(X, in_fit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    528\u001b[0m statistics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatistics_\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m statistics\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:329\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m new_ve \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 329\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ve\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_fit:\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;66;03m# Use the dtype seen in `fit` for non-`fit` conversion\u001b[39;00m\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_dtype \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:312\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    309\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    313\u001b[0m         X,\n\u001b[0;32m    314\u001b[0m         reset\u001b[38;5;241m=\u001b[39min_fit,\n\u001b[0;32m    315\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    316\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    317\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m    318\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy,\n\u001b[0;32m    319\u001b[0m     )\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not convert\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ve):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    510\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    516\u001b[0m ):\n\u001b[0;32m    517\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \n\u001b[0;32m    519\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    583\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    584\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    585\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:506\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    502\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m     )\n\u001b[1;32m--> 506\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- COST\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "train_url = \"https://github.com/FlipRoboTechnologies/ML-Datasets/raw/main/Restaurant%20Food%20Cost/Data_Train.xlsx\"\n",
    "test_url = \"https://github.com/FlipRoboTechnologies/ML-Datasets/raw/main/Restaurant%20Food%20Cost/Data_Test.xlsx\"\n",
    "\n",
    "train_data = pd.read_excel(train_url)\n",
    "test_data = pd.read_excel(test_url)\n",
    "\n",
    "print(train_data.head())\n",
    "\n",
    "print(train_data.info())\n",
    "\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "print(train_data.describe(include='all'))\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "train_data = pd.DataFrame(imputer.fit_transform(train_data), columns=train_data.columns)\n",
    "test_data = pd.DataFrame(imputer.transform(test_data), columns=test_data.columns)\n",
    "\n",
    "label_encoders = {}\n",
    "categorical_cols = ['TITLE', 'CUISINES', 'TIME', 'CITY', 'LOCALITY']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    train_data[col] = label_encoders[col].fit_transform(train_data[col])\n",
    "    test_data[col] = label_encoders[col].transform(test_data[col])\n",
    "\n",
    "X = train_data.drop(['RESTAURANT_ID', 'COST'], axis=1)\n",
    "y = train_data['COST']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Validation RMSE: {rmse:.2f}\")\n",
    "\n",
    "X_test = test_data.drop(['RESTAURANT_ID'], axis=1)\n",
    "\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({'RESTAURANT_ID': test_data['RESTAURANT_ID'], 'COST': test_predictions})\n",
    "\n",
    "submission.to_csv('restaurant_cost_predictions.csv', index=False)\n",
    "print(\"Predictions saved to restaurant_cost_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84de204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
